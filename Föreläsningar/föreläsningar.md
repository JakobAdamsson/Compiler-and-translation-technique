# Föreläsning 2
## Intro
The Lexical analysis also known as the scanner and is responsible for atomic language constructs(numbers, identifiers, reserved keywords). The lexer outputs a tokestream and the tokenanalyzer takes the stream and checks if it is correct based on some specific language grammar. The parser outputs a parsertree  
  
The semantic analysis which checks the correctness of the program with respect of the semantic of the program. The main role is to do typechecking(is a typechecker).

The symboltable stores information about the program. Such information might be variables, type and the scope of the variable.

## Lexical analysis overview
The first step in any compiler is the scanning phase(lexing analysis). It analyses raw source code and the main objective of the group the characters in a series of meaningful chuncks(**tokens**). The main role of the lexer is to scan and group toghether so that we can represent something. Each of theses groups are called **leximes**. Besides grouping and identifieng tokens it also has the role of discarding unessisacy constructs(e.g whitespaces). A token is an object that defines the comprises the name of the token and the value of the lexime. A lexime is a seqence of characters. An **identifier** is a sequence of characters that begins with a letter.

## Formal languages
**A formal language has:**  
- Symbols: The smallest identifiable units(characters, digits)
- Alphabet: $\sum$ - a set of symbols
- Strings: a fnite a sequence of symbols from $\sum$
  - The emtpty string $\epsilon$ is a special string
  - |s| - lenght of the string

**Definition: A language L is a possibly infinite set of strings over a finite alphabet  $\sum$, denoted as L($\sum$)**
- E.g {xy, xyxy, xyxyxy, ...} is a language over $\sum = (x,y)$
- E.g any binary number is a string over the alphabet $\sum = {0, 1}$ with symbols 0 and 1
- E.g ASCII is an important example of an alphabet


## Formal language examples
**Let l = {A, B, ..., Z, a, b, ...., z} and D = {0, 1, ..., 9}

1. $L U D$ - the set of letters and digits
2. $LD$ - the set of strings of lenght 2, consisting of one letter followed by one digit
3. $L^4$ is the set of all 4-letter strings
4. $L^*$ is the set of all strings of letters, including the empty string
5. $L(L U D)^*$ is the set of all strings of letters and digits beginning wit ha letter
6. $d^+$ is the set of all strings of one or more digits

## Regular language and regular experssions
**Regular expressions:**  
Union: $A U B = a | b$ read as a or b  
Concatienation: $a * b = ab$ read as a followed by b  
Kleene closure: $a*$ read as zero or more a's

**Shortcuts**  
Positive closure: $a+ = aa*$ read as one or more occurences of a  
Optionally: $a? = \epsilon / a$ read as zero or mroe occurences of a  
range: $[0-9] = 0|1|2|3|4|5|6|7|8|9,  
[a-cA-C] = a|b|c|A|B|C$

**Precedence**  
E.g, $ab*|b*a = (a(b*))$  |  $((b*)a)$


**A finite automata is basically the scanner or the set of rules in the flex file**


#### Regular experssions to DFA: Concatenation
'append' the two expressions together.

#### Regular experssions to DFA: Union
Add multiple transitions for each choice

#### Regular experssions to DFA: Closure
Kleene closure represents a loop in the DFA, $\epsilon$ is accepted state and when concatenation, closure can be skipepd. Is marked with *


## Handeling troublesome DFAs
If we have $x*x$ this would lead to an illegal DFA, why?: Because there are non-unique labels from state 0into state 1. Solution would be: $x*x = xx*$

**A valid DFA needs to have unique edges! This is due to we need to know which edge to pick. -> non deterministic finite automata**

## Nondeterministic finite automata(NFA)
Non-determinism: multiple choices, one of which is right  
Determinsim: One right choice only

### Powerset construction algorithm(NFA -> DFA)
Algorithm outline:
- DFA state 0 = all $\epsilon$ equivalent states of NFA 0
- Which states can  be reached from DFA 0 on input x, y, z, ...?
  - => new DFA states 1, 2, 3, ...
- Repeat (2) with DFA states 1, 2, 3, ... untill there are no new DFA states.



## Implementation of DFAs:
- DFA as control flow: switch cases, if else
- Data driven - The DFA is stored in data structures and a function reads the data structure and performs the necessary transitions
- OOP based- The regular expressions and the operators are classes and objects



## Flex special characters
![](bilder/flex.png)
![](bilder/amb.png)


# Föreläsning 3 - Syntax analyis
## The role of a syntax analysis - parsing
- Input_ program representation(token sequence) generated by the lexer
- Output: parse(syntax) tree
- A parse tree comprises nodes and non-labeled edges
- The output of the parser will be used by the rest of the compiler

## Types of parsers
### Top down parsers
- Starts with a symbol and builds the tree in a top-down way
- Can handle a restricted set of grammars


### Bottom up parsers
- Recognizes subsequences of tokens and build the tree bottom up
- Can handle a restricted set of grammars

### Universal parsers
- Can parse any context free grammar
- To slow to beof any particular use

## Context free grammars
A language must:
- Include all correct programs
- Exlude all incorrect programs

Context free grammars are always used to define programming languages. A context free grammar comprises:
- Terminals ( (,), class, public, static, ... )
- Nonterminals (MainClass, ClassDeclaration, Identifier, ...)
- Productions(Goal, Mainclass, ClassDeclaration, ...)
  - **Nonterminal head (left side); ::= or ->; **Body**(right side)
- Start Symbol(Goal )

#### A context free grammar is a quadruple G = (T, N, P, S) where:
- T - is the set of terminals(tokens)
- N - is the set of non terminals(syntatic constructions)
- P:N -> (N U T)* - is the set of productions (non terminal definitions)
- S € N - is the start symbol

## Rewrites, production and reduction rules
```c
X -> YZ
Y -> "Hello" | "Goodbye"
Z -> "You
```
### Rewrite:
- We can replace X with YZ
- We can replace YZ with X

Production rules:
- Working f rom start symbol towards language strings. E.g X -> YZ
- Characteristic of top down parsers

Reduction rules
- Start with the string and fold up the string towards the start symbol. E.g, YZ -> X
- Characteristic of bottom up parsers

## Backus naur form
A meta language(language made for defining other languages)  
Bison is a syntax variation of BNF where BNF is a repeated productions with the same left hand side (A->$\alpha$, A_>$\beta$) can be written using BNF as $\alpha$|$\beta$

Terminals are the basic building blocks of the language. They represent the individual characters, such as keywords, operators, and punctuation, that make up the source code. Examples of terminals in the C programming language include "int", "+", and ";".

Non-terminals, on the other hand, are used to group terminals together into larger, more complex structures. These structures are often called productions, and they represent the different parts of the source code, such as statements, expressions, and declarations. Examples of non-terminals in the C programming language include "statement", "expression", and "declaration". 


## Derivations
- Used to show that a string is in the language of a given grammar
- Begin with the start symbol and repeatedly rewrite any non-terminal with the body of one of the productions(Typ regler)

Ex:
```
Productions:
1. E -> id
2. E -> (E)
3. E -> E + E
4. E -> E * E


E -(4)> E*E -(1)> E * id -(3)> E + E * id -(1)> E + id * id -(1)> id + id * id
```

## Parse trees
A parse tree is a graphical representation of a derivation constructed by connecting each symbol(terminal or nonterminal) to the one form which it is derived.
 


## Lexical vs Syntatic analysis
Lexical analysis identifies atomic lanugage constructs, uses regular expressions, uses operators such as concatenation and union and Lexical analysis is implemented sing DFA or NFA

Syntatic analysis
Defines the structure of the language and uses context free grammars. Uses operators like concationation, union and nesting and is implemented using push down automata
 

A pushdown automata (PDA) is a type of automata that, in addition to a finite set of states and a finite set of input symbols, also has a stack, which is a data structure that can be thought of as a last-in, first-out (LIFO) buffer. The automaton can push symbols onto the stack as it reads the input, and it can also pop symbols off the stack in response to the input. PDAs are used in the theory of computation and in the design of compilers and other programming language processors. They are used to recognize context-free languages, which are a subset of all formal languages.

## Problems
**General case**
```c
A -> A$\alpha$ | $\beta$

A -> $\beta$A'
A' -> $\alpha$A'|$\epsilon$
```
#### Ambiguity
Ambigous grammas can derive more than one different parse tree fromn the same string.  
To solove ambiguty we need semantic information to resolve the ambiguity, basicall rewrite our productions

#### Recursion
A grammar is recursive if it has a production rule A that can deriva a sequence containing the same non terminal A

**Left recursion**  
A grammar is left recursive if it has a non terminal A such that there is a derivation A -> A$\alpha$ for some string $\alpha$. Topdown parsers cannot handle left recursion -> transformation is needed.



## Left factorization
Left factorization is a transformation technique suitable for predictive top down parsing. Very useful when the choice between two alternatives is not clear.

The gerneral case:
A -> $\alpha$$\beta_1$ | $\alpha$$\beta_2$
A -> $\alpha$A'
A' -> $\beta_1$ | $\beta_2$


# Föreläsning 4 Top down parsing
Most compilers use Top-down parser and bottom up parser

In both of them the input is read left to right but top-down parsers read from the root and down while the bottom up parsers reads from the leafnodes up to the root(input string).

## Top-down parsing
Full backtracking - Try all possibilities and backtrack on the ones that fail to produce the result  
Without backtracking - recursive decent(implemented by writing recusive function for all productions).

## LL(1) parsing
A simple predictive parser: 
- L - reading the input left to right
- L - Leftmost derivation
- (1) - One token lookahead

The choice of the production rule to be used on each non-ternimal is done by looking at the next token of the input

LL(1) requires elemination of ambiguity, left recursion and non determinism from the grammar. For execution it needs a **parse table, a stack and an input buffer** 

Works by(outline):
- Start: Push start symbol to the stack, the bottom of the stack and the end of the input has a $ to indicate the termination of parsing
- Parsing: If top of stack(TOP) is equal to the head of the buffer(LA, lookahead) perform **reduce**, else **shift**
- Shift: Rewrite the top element(non-terminal) in the stack wit hthe production rule from M[TOP, LA]
- Reduce: Pop the top element(terminal) from the stack and consume the first symbol from the input buffer.

## Constructing a parse table: FIRST function
![](bilder/FIRST.png)

## Constructing a parse table: FOLLOWS function
![](bilder/FOLLOW.png)

## Constructing the parse table
![](bilder/CONSTRUCT.png)

## Bottom up LR parsers
LR tree construction where L is the reading of the input left to right and R is the right most derivation. It can parse larger class of grammars where left recursion is not an issue while constructing the automata is more complex.

## Reduction rules
- Starts on the terminal
- Application of rewrites(right most derivation)
- Stops on the start symbol(the final form matches the source)
- Challanges: what to reduce?

# Semantic analysis (for assignment 2)
Symbol table: Constructed by visiting the AST.  
Semantic analysis: Performed by traversing the AST and using the information from the symbol table

